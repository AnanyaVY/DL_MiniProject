{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2332307,
          "sourceType": "datasetVersion",
          "datasetId": 891819
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'tuberculosis-tb-chest-xray-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F891819%2F2332307%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240508%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240508T175238Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D16a2bc7d3e4b8c77a6e91e97fb699e08780ca08ffa34caa4a7654a6ef3a1b5a846d2458bf4e04043df6dd00450ea0ff3a72b687375f90dde180d379c4df43cd98fe8b62d8254a44b7a97e43196f957aa00f981abceffebd0fb1a9cb7f72d6a1fffa1a8377104b6d1a751b6901aaca5fbf45a9cb6280ea1b73e07957e41b64508ebfaf9295924254f8c782f057dff851aa9e0d870dc69b38d84a2a2dad2fe4b3697c566787d46c3db737919e16d8dc008dc3a79c341cd9ea064b0f12b8a6b08264cdf6e8fdac8ce4666bb2c5581e6094095dd8803cb1d926bed00f2b297c209e713de0cdb42a099ea9c6b44e9fad341499436dd17a416fb703e18d2f0cb95a87f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGE1k2LCVgz9",
        "outputId": "53b06ef9-bd2d-412f-d33c-fff03241452e"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/891819/2332307/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240508%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240508T175238Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=16a2bc7d3e4b8c77a6e91e97fb699e08780ca08ffa34caa4a7654a6ef3a1b5a846d2458bf4e04043df6dd00450ea0ff3a72b687375f90dde180d379c4df43cd98fe8b62d8254a44b7a97e43196f957aa00f981abceffebd0fb1a9cb7f72d6a1fffa1a8377104b6d1a751b6901aaca5fbf45a9cb6280ea1b73e07957e41b64508ebfaf9295924254f8c782f057dff851aa9e0d870dc69b38d84a2a2dad2fe4b3697c566787d46c3db737919e16d8dc008dc3a79c341cd9ea064b0f12b8a6b08264cdf6e8fdac8ce4666bb2c5581e6094095dd8803cb1d926bed00f2b297c209e713de0cdb42a099ea9c6b44e9fad341499436dd17a416fb703e18d2f0cb95a87f to path /kaggle/input/tuberculosis-tb-chest-xray-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUE9Z7QxBp2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.applications.resnet import ResNet50, preprocess_input as resnet_preprocess_input\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess_input\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input as vgg19_preprocess_input\n",
        "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:52:49.149239Z",
          "iopub.execute_input": "2024-05-05T07:52:49.149669Z",
          "iopub.status.idle": "2024-05-05T07:52:49.16297Z",
          "shell.execute_reply.started": "2024-05-05T07:52:49.149629Z",
          "shell.execute_reply": "2024-05-05T07:52:49.161807Z"
        },
        "trusted": true,
        "id": "F4iUWRJ6Vg0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(base_model, preprocess_input):\n",
        "    base_model.trainable = False\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:52:49.165243Z",
          "iopub.execute_input": "2024-05-05T07:52:49.165733Z",
          "iopub.status.idle": "2024-05-05T07:52:49.187773Z",
          "shell.execute_reply.started": "2024-05-05T07:52:49.165695Z",
          "shell.execute_reply": "2024-05-05T07:52:49.185961Z"
        },
        "trusted": true,
        "id": "2voxO97BVg0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate model\n",
        "def evaluate_model(model, val_data):\n",
        "    prediction = model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "    prediction = (prediction > 0.5)\n",
        "    pred2 = [i[1] for i in prediction]\n",
        "    cm = confusion_matrix(val_data.classes, pred2)\n",
        "    plot_confusion_matrix(cm, figsize=(5,5))\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(val_data.classes, pred2))\n",
        "    print(classification_report(val_data.classes, pred2))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:52:49.189581Z",
          "iopub.execute_input": "2024-05-05T07:52:49.190563Z",
          "iopub.status.idle": "2024-05-05T07:52:49.20599Z",
          "shell.execute_reply.started": "2024-05-05T07:52:49.190517Z",
          "shell.execute_reply": "2024-05-05T07:52:49.204432Z"
        },
        "trusted": true,
        "id": "rRAdV2-tVg0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data directories\n",
        "base_dir = \"/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database\"\n",
        "\n",
        "# ImageDataGenerators\n",
        "train_datagen = ImageDataGenerator(rescale=1/255, zoom_range=0.3, rotation_range=50,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,\n",
        "                                   horizontal_flip=True, fill_mode='nearest', validation_split=0.2)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:52:49.207666Z",
          "iopub.execute_input": "2024-05-05T07:52:49.208325Z",
          "iopub.status.idle": "2024-05-05T07:52:49.221551Z",
          "shell.execute_reply.started": "2024-05-05T07:52:49.208105Z",
          "shell.execute_reply": "2024-05-05T07:52:49.22031Z"
        },
        "trusted": true,
        "id": "7Rw_LxGwVg0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_data = train_datagen.flow_from_directory(base_dir,\n",
        "                                               target_size=(200, 200),\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=20,\n",
        "                                               subset='training')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "val_data = val_datagen.flow_from_directory(base_dir,\n",
        "                                           target_size=(200, 200),\n",
        "                                           class_mode='categorical',\n",
        "                                           batch_size=20,\n",
        "                                           subset='validation')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:52:49.225252Z",
          "iopub.execute_input": "2024-05-05T07:52:49.225663Z",
          "iopub.status.idle": "2024-05-05T07:52:51.168597Z",
          "shell.execute_reply.started": "2024-05-05T07:52:49.22563Z",
          "shell.execute_reply": "2024-05-05T07:52:51.167402Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLtKs3ubVg0J",
        "outputId": "c33c31f4-6792-45ff-e4ba-2ca02c3fe8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3360 images belonging to 2 classes.\n",
            "Found 840 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50\n",
        "resnet_model = create_model(ResNet50(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                             resnet_preprocess_input)\n",
        "resnet_history = resnet_model.fit(train_data,\n",
        "                                  steps_per_epoch=train_data.samples // train_data.batch_size,\n",
        "                                  validation_data=val_data,\n",
        "                                  validation_steps=val_data.samples // val_data.batch_size,\n",
        "                                  epochs=10,\n",
        "                                  verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:52:51.170036Z",
          "iopub.execute_input": "2024-05-05T07:52:51.170486Z",
          "iopub.status.idle": "2024-05-05T07:53:12.611521Z",
          "shell.execute_reply.started": "2024-05-05T07:52:51.170447Z",
          "shell.execute_reply": "2024-05-05T07:53:12.609436Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk-OW-rqVg0K",
        "outputId": "a7d8a196-feb2-4b64-d6ed-bb04454cc7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "168/168 [==============================] - 666s 4s/step - loss: 0.4632 - accuracy: 0.8333 - val_loss: 0.4478 - val_accuracy: 0.8333\n",
            "Epoch 2/10\n",
            "168/168 [==============================] - 651s 4s/step - loss: 0.4481 - accuracy: 0.8336 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 3/10\n",
            "168/168 [==============================] - 645s 4s/step - loss: 0.4466 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "168/168 [==============================] - 646s 4s/step - loss: 0.4436 - accuracy: 0.8333 - val_loss: 0.4591 - val_accuracy: 0.8333\n",
            "Epoch 5/10\n",
            "168/168 [==============================] - 659s 4s/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4496 - val_accuracy: 0.8333\n",
            "Epoch 6/10\n",
            " 66/168 [==========>...................] - ETA: 5:13 - loss: 0.4214 - accuracy: 0.8424"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19\n",
        "vgg19_model = create_model(VGG19(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                            vgg19_preprocess_input)\n",
        "vgg19_history = vgg19_model.fit(train_data,\n",
        "                                steps_per_epoch=train_data.samples // train_data.batch_size,\n",
        "                                validation_data=val_data,\n",
        "                                validation_steps=val_data.samples // val_data.batch_size,\n",
        "                                epochs=10,\n",
        "                                verbose=1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T07:53:12.61513Z",
          "iopub.status.idle": "2024-05-05T07:53:12.615612Z",
          "shell.execute_reply.started": "2024-05-05T07:53:12.615373Z",
          "shell.execute_reply": "2024-05-05T07:53:12.615396Z"
        },
        "trusted": true,
        "id": "V8ZgbO3FVg0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InceptionV3\n",
        "inception_model = create_model(InceptionV3(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                                inception_preprocess_input)\n",
        "inception_history = inception_model.fit(train_data,\n",
        "                                        steps_per_epoch=train_data.samples // train_data.batch_size,\n",
        "                                        validation_data=val_data,\n",
        "                                        validation_steps=val_data.samples // val_data.batch_size,\n",
        "                                        epochs=10,\n",
        "                                        verbose=1)"
      ],
      "metadata": {
        "id": "mP0Bmb8s4HTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xception\n",
        "xception_model = create_model(Xception(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                               xception_preprocess_input)\n",
        "xception_history = xception_model.fit(train_data,\n",
        "                                      steps_per_epoch=train_data.samples // train_data.batch_size,\n",
        "                                      validation_data=val_data,\n",
        "                                      validation_steps=val_data.samples // val_data.batch_size,\n",
        "                                      epochs=10,\n",
        "                                      verbose=1)"
      ],
      "metadata": {
        "id": "2WKabZsK4Oj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting accuracies\n",
        "plt.plot(resnet_history.history['val_accuracy'], label='ResNet50')\n",
        "plt.plot(inception_history.history['val_accuracy'], label='InceptionV3')\n",
        "plt.plot(vgg19_history.history['val_accuracy'], label='VGG19')\n",
        "plt.plot(xception_history.history['val_accuracy'], label='Xception')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Model Accuracies Comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8JcRMUun4cFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_results(model, val_data, model_name):\n",
        "    prediction = model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "    prediction = (prediction > 0.5)\n",
        "    pred2 = [i[1] for i in prediction]\n",
        "    cm = confusion_matrix(val_data.classes, pred2)\n",
        "    plot_confusion_matrix(cm, figsize=(5,5))\n",
        "\n",
        "    accuracy = accuracy_score(val_data.classes, pred2)\n",
        "    print(f\"Accuracy of {model_name}: {accuracy}\")\n",
        "    print(f\"Classification Report of {model_name}:\\n{classification_report(val_data.classes, pred2)}\\n\\n\")\n",
        "\n",
        "print_model_results(resnet_model, val_data, \"ResNet50\")\n",
        "print_model_results(vgg19_model, val_data, \"VGG19\")\n",
        "print_model_results(inception_model, val_data, \"InceptionV3\")\n",
        "print_model_results(xception_model, val_data, \"Xception\")\n"
      ],
      "metadata": {
        "id": "X83w0_UxjAZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model is already defined and trained\n",
        "model = create_model(ResNet50(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                             resnet_preprocess_input)\n",
        "\n",
        "\n",
        "# Now you can use the model to make predictions\n",
        "prediction = model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "prediction = (prediction > 0.5)\n",
        "pred2 = [i[1] for i in prediction]\n",
        "\n",
        "# Now you can calculate the accuracy\n",
        "accuracy_resnet = accuracy_score(val_data.classes, pred2)\n",
        "\n"
      ],
      "metadata": {
        "id": "rol32zN36Lze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19\n",
        "vgg19_model = create_model(VGG19(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                            vgg19_preprocess_input)\n",
        "\n",
        "\n",
        "# Now you can use the VGG19 model to make predictions\n",
        "prediction_vgg19 = vgg19_model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "prediction_vgg19 = (prediction_vgg19 > 0.5)\n",
        "pred2_vgg19 = [i[1] for i in prediction_vgg19]\n",
        "\n",
        "# Now you can calculate the accuracy for VGG19\n",
        "accuracy_vgg19 = accuracy_score(val_data.classes, pred2_vgg19)\n",
        "\n",
        "# Similarly, you can do the same for InceptionV3 and Xception\n"
      ],
      "metadata": {
        "id": "xDCFHvzn7mzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InceptionV3\n",
        "inception_model = create_model(InceptionV3(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                                inception_preprocess_input)\n",
        "\n",
        "\n",
        "# Now you can use the InceptionV3 model to make predictions\n",
        "prediction_inception = inception_model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "prediction_inception = (prediction_inception > 0.5)\n",
        "pred2_inception = [i[1] for i in prediction_inception]\n",
        "\n",
        "# Now you can calculate the accuracy for InceptionV3\n",
        "accuracy_inception = accuracy_score(val_data.classes, pred2_inception)\n"
      ],
      "metadata": {
        "id": "IJmg9_tB7pUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xception\n",
        "xception_model = create_model(Xception(input_shape=(200, 200, 3), include_top=False, weights='imagenet'),\n",
        "                               xception_preprocess_input)\n",
        "\n",
        "\n",
        "# Now you can use the Xception model to make predictions\n",
        "prediction_xception = xception_model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "prediction_xception = (prediction_xception > 0.5)\n",
        "pred2_xception = [i[1] for i in prediction_xception]\n",
        "\n",
        "# Now you can calculate the accuracy for Xception\n",
        "accuracy_xception = accuracy_score(val_data.classes, pred2_xception)\n"
      ],
      "metadata": {
        "id": "vlQCMRoB7wCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Calculate accuracy scores\n",
        "accuracy_resnet = accuracy_score(val_data.classes, pred2)\n",
        "accuracy_vgg19 = accuracy_score(val_data.classes, pred2)\n",
        "accuracy_inception = accuracy_score(val_data.classes, pred2)\n",
        "accuracy_xception = accuracy_score(val_data.classes, pred2)\n",
        "\n",
        "# Example classification report (replace this with your actual classification reports)\n",
        "classification_report_resnet = classification_report(val_data.classes, pred2, output_dict=True)\n",
        "classification_report_vgg19 = classification_report(val_data.classes, pred2, output_dict=True)\n",
        "classification_report_inception = classification_report(val_data.classes, pred2, output_dict=True)\n",
        "classification_report_xception = classification_report(val_data.classes, pred2, output_dict=True)\n",
        "\n",
        "# Extract precision, recall, and f1-score from classification report\n",
        "precision_resnet = classification_report_resnet['macro avg']['precision']\n",
        "precision_vgg19 = classification_report_vgg19['macro avg']['precision']\n",
        "precision_inception = classification_report_inception['macro avg']['precision']\n",
        "precision_xception = classification_report_xception['macro avg']['precision']\n",
        "\n",
        "recall_resnet = classification_report_resnet['macro avg']['recall']\n",
        "recall_vgg19 = classification_report_vgg19['macro avg']['recall']\n",
        "recall_inception = classification_report_inception['macro avg']['recall']\n",
        "recall_xception = classification_report_xception['macro avg']['recall']\n",
        "\n",
        "f1_score_resnet = classification_report_resnet['macro avg']['f1-score']\n",
        "f1_score_vgg19 = classification_report_vgg19['macro avg']['f1-score']\n",
        "f1_score_inception = classification_report_inception['macro avg']['f1-score']\n",
        "f1_score_xception = classification_report_xception['macro avg']['f1-score']\n",
        "\n",
        "# Create a DataFrame to store the model evaluation results\n",
        "model_results = pd.DataFrame({\n",
        "    'Model': ['ResNet50', 'VGG19', 'InceptionV3', 'Xception'],\n",
        "    'Accuracy': [accuracy_resnet, accuracy_vgg19, accuracy_inception, accuracy_xception],\n",
        "    'Precision': [precision_resnet, precision_vgg19, precision_inception, precision_xception],\n",
        "    'Recall': [recall_resnet, recall_vgg19, recall_inception, recall_xception],\n",
        "    'F1 Score': [f1_score_resnet, f1_score_vgg19, f1_score_inception, f1_score_xception]\n",
        "})\n",
        "\n",
        "# Melt the DataFrame to 'long' format for visualization\n",
        "model_results_melted = pd.melt(model_results, id_vars=['Model'], var_name='Metric', value_name='Score')\n",
        "\n",
        "# Plot using Seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=model_results_melted, x='Model', y='Score', hue='Metric', palette='YlGnBu')\n",
        "plt.title('Comparison of Pretrained Models')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Score')\n",
        "plt.legend(title='Metric')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Td2ETwv1tEmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M6dVhxwJe3H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = {\n",
        "    'ResNet50': resnet_model,\n",
        "    'InceptionV3': inception_model,\n",
        "    'VGG19': vgg19_model,\n",
        "    'Xception': xception_model\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Model: {name}\")\n",
        "    print_model_results(model, val_data, name)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    prediction = model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=1)\n",
        "    prediction = (prediction > 0.5)\n",
        "    pred2 = [i[1] for i in prediction]\n",
        "    y_true = val_data.classes\n",
        "    cm = confusion_matrix(y_true, pred2)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=val_data.class_indices.keys(), yticklabels=val_data.class_indices.keys())\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.ylabel('True labels')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KpnkJ4i4-dnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50, VGG19, InceptionV3, Xception\n",
        "\n",
        "# ResNet50\n",
        "resnet_model = ResNet50(weights='imagenet')\n",
        "print(\"ResNet50 Summary:\")\n",
        "resnet_model.summary()\n",
        "\n",
        "# VGG19\n",
        "vgg19_model = VGG19(weights='imagenet')\n",
        "print(\"\\nVGG19 Summary:\")\n",
        "vgg19_model.summary()\n",
        "\n",
        "# InceptionV3\n",
        "inception_model = InceptionV3(weights='imagenet')\n",
        "print(\"\\nInceptionV3 Summary:\")\n",
        "inception_model.summary()\n",
        "\n",
        "# Xception\n",
        "xception_model = Xception(weights='imagenet')\n",
        "print(\"\\nXception Summary:\")\n",
        "xception_model.summary()\n"
      ],
      "metadata": {
        "id": "UoESBYb45vzi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}